{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以Transformers套件實作填漏字(Masked Language Modeling)功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入相關套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base (https://huggingface.co/distilroberta-base)\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\"fill-mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.17927508056163788,\n",
      "  'sequence': 'HuggingFace is creating a tool that the community uses to solve '\n",
      "              'NLP tasks.',\n",
      "  'token': 3944,\n",
      "  'token_str': ' tool'},\n",
      " {'score': 0.11349443346261978,\n",
      "  'sequence': 'HuggingFace is creating a framework that the community uses to '\n",
      "              'solve NLP tasks.',\n",
      "  'token': 7208,\n",
      "  'token_str': ' framework'},\n",
      " {'score': 0.05243544280529022,\n",
      "  'sequence': 'HuggingFace is creating a library that the community uses to '\n",
      "              'solve NLP tasks.',\n",
      "  'token': 5560,\n",
      "  'token_str': ' library'},\n",
      " {'score': 0.0349353663623333,\n",
      "  'sequence': 'HuggingFace is creating a database that the community uses to '\n",
      "              'solve NLP tasks.',\n",
      "  'token': 8503,\n",
      "  'token_str': ' database'},\n",
      " {'score': 0.028602443635463715,\n",
      "  'sequence': 'HuggingFace is creating a prototype that the community uses to '\n",
      "              'solve NLP tasks.',\n",
      "  'token': 17715,\n",
      "  'token_str': ' prototype'}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(nlp(f\"HuggingFace is creating a {nlp.tokenizer.mask_token} \" + \\\n",
    "           \"that the community uses to solve NLP tasks.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結合Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc53882e96a54ea0a43a3cfbd1a5af10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/251M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 載入相關套件\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# 結合分詞器(Tokenizer)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"distilbert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推測答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distilled models are smaller than the models they mimic. Using them instead of the large versions would help reduce our carbon footprint.\n",
      "Distilled models are smaller than the models they mimic. Using them instead of the large versions would help increase our carbon footprint.\n",
      "Distilled models are smaller than the models they mimic. Using them instead of the large versions would help decrease our carbon footprint.\n",
      "Distilled models are smaller than the models they mimic. Using them instead of the large versions would help offset our carbon footprint.\n",
      "Distilled models are smaller than the models they mimic. Using them instead of the large versions would help improve our carbon footprint.\n"
     ]
    }
   ],
   "source": [
    "sequence = f\"Distilled models are smaller than the models they mimic. \" + \\\n",
    "    f\"Using them instead of the large versions would help {tokenizer.mask_token} \" + \\\n",
    "    \"our carbon footprint.\"\n",
    "inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
    "mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "token_logits = model(**inputs).logits\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "for token in top_5_tokens:\n",
    "    print(sequence.replace(tokenizer.mask_token, tokenizer.decode([token])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
